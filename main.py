import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import math
import tempfile
import os

# MediaPipeã®åˆæœŸåŒ–
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_face_mesh = mp.solutions.face_mesh

class VideoAnalyzer:
    def __init__(self):
        self.pose = mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.face_mesh = mp_face_mesh.FaceMesh(
            static_image_mode=False,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.hip_angles = []
        self.max_angle = 0
        self.min_angle = float('inf')
        self.fixed_head_y = None
        
        # å‰æ–¹åœæ­¢æ¤œçŸ¥ç”¨
        self.recent_angles = []
        self.pause_detection_window = 8
        self.pause_threshold = 1.0
        self.is_paused_forward = False
        self.pause_counter = 0
    
    def calculate_angle(self, point1, point2, point3):
        """3ç‚¹é–“ã®è§’åº¦ã‚’è¨ˆç®—"""
        vector1 = np.array(point1) - np.array(point2)
        vector2 = np.array(point3) - np.array(point2)
        
        cosine_angle = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))
        angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
        
        return np.degrees(angle)
    
    def draw_head_horizontal_line(self, image, head_y=None):
        """å›ºå®šã®é ­ã®é«˜ã•ã«æ°´å¹³ç·šã‚’æç”»"""
        height, width = image.shape[:2]
        if self.fixed_head_y is None and head_y is not None:
            self.fixed_head_y = head_y
        if self.fixed_head_y is not None:
            cv2.line(image, (0, int(self.fixed_head_y)), (width, int(self.fixed_head_y)), (0, 255, 0), 3)
            cv2.putText(image, f"Head Reference: {int(self.fixed_head_y)}px", (10, int(self.fixed_head_y) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        return image
    
    def draw_hip_angle(self, image, angle, position):
        """è…°ã®è§’åº¦ã‚’æç”»ï¼ˆå¤§ããªãƒ•ã‚©ãƒ³ãƒˆï¼‰"""
        text_size = cv2.getTextSize(f"Hip Angle: {angle:.1f} deg", cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]
        cv2.rectangle(image, (position[0] - 10, position[1] - text_size[1] - 15),
                     (position[0] + text_size[0] + 10, position[1] + 10), (0, 0, 0), -1)
        cv2.rectangle(image, (position[0] - 10, position[1] - text_size[1] - 15),
                     (position[0] + text_size[0] + 10, position[1] + 10), (255, 255, 255), 2)
        cv2.putText(image, f"Hip Angle: {angle:.1f} deg", position,
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 3)
        return image
    
    def draw_eye_gaze(self, image, face_landmarks):
        """çµ¶å¯¾ã«è¦‹ãˆã‚‹ç›®ç·šçŸ¢å°è¡¨ç¤º"""
        height, width = image.shape[:2]
        center_x = width // 2
        center_y = height // 3
        arrow_end_x = center_x + 80
        arrow_end_y = center_y
        gaze_status = "STRAIGHT"
        status_color = (0, 255, 0)
        
        if face_landmarks:
            try:
                nose_tip = face_landmarks.landmark[1]
                forehead = face_landmarks.landmark[10]
                chin = face_landmarks.landmark[175]
                
                nose_x = int(nose_tip.x * width)
                nose_y = int(nose_tip.y * height)
                forehead_y = int(forehead.y * height)
                chin_y = int(chin.y * height)
                
                horizontal_offset = nose_x - (width // 2)
                face_height = chin_y - forehead_y
                vertical_offset = nose_y - (forehead_y + face_height / 2)
                
                vertical_ratio = vertical_offset / (face_height * 0.3) if face_height > 0 else 0
                horizontal_ratio = horizontal_offset / (width * 0.15)
                
                h_direction = 0 if abs(horizontal_ratio) < 0.5 else (1 if horizontal_ratio > 0 else -1)
                v_direction = 0 if abs(vertical_ratio) < 0.5 else (1 if vertical_ratio > 0 else -1)
                
                if h_direction == 0 and v_direction == 0:
                    gaze_status = "STRAIGHT"
                    status_color = (0, 255, 0)
                else:
                    status_parts = []
                    if v_direction == -1: status_parts.append("UP")
                    elif v_direction == 1: status_parts.append("DOWN")
                    if h_direction == -1: status_parts.append("LEFT")
                    elif h_direction == 1: status_parts.append("RIGHT")
                    gaze_status = " + ".join(status_parts)
                    status_color = (0, 255, 255)
                
                arrow_length = 80
                arrow_end_x = center_x + (h_direction * arrow_length)
                arrow_end_y = center_y + (v_direction * arrow_length)
                
                if h_direction == 0 and v_direction == 0:
                    arrow_end_x = center_x + 50
                    arrow_end_y = center_y
            except:
                pass
        
        cv2.arrowedLine(image, (center_x, center_y), (arrow_end_x, arrow_end_y), (0, 0, 0), 20, tipLength=0.3)
        cv2.arrowedLine(image, (center_x, center_y), (arrow_end_x, arrow_end_y), (255, 255, 255), 15, tipLength=0.3)
        cv2.arrowedLine(image, (center_x, center_y), (arrow_end_x, arrow_end_y), status_color, 10, tipLength=0.3)
        cv2.circle(image, (center_x, center_y), 15, (255, 0, 0), -1)
        cv2.circle(image, (center_x, center_y), 18, (255, 255, 255), 3)
        
        return image
    
    def detect_forward_pause(self, hip_angle):
        """å‰æ–¹åœæ­¢æ¤œçŸ¥ï¼ˆå³ã—ã„åˆ¤å®šï¼‰"""
        self.recent_angles.append(hip_angle)
        if len(self.recent_angles) > self.pause_detection_window:
            self.recent_angles.pop(0)
        
        if len(self.recent_angles) >= self.pause_detection_window:
            angle_std = np.std(self.recent_angles)
            avg_angle = np.mean(self.recent_angles)
            
            is_forward_position = avg_angle > np.mean(self.hip_angles) + 0.25 * np.std(self.hip_angles) if len(self.hip_angles) > 10 else True
            is_stable = angle_std < self.pause_threshold
            
            if is_forward_position and is_stable:
                if not self.is_paused_forward:
                    self.is_paused_forward = True
                    self.pause_counter = 1
                else:
                    self.pause_counter += 1
            else:
                self.is_paused_forward = False
                self.pause_counter = 0
    
    def draw_pause_indicator(self, image):
        """å‰æ–¹åœæ­¢ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’æç”»"""
        if self.is_paused_forward and self.pause_counter > 2:
            height, width = image.shape[:2]
            
            if self.pause_counter < 10:
                color = (0, 255, 0)
                status = "GOOD PAUSE"
            elif self.pause_counter < 20:
                color = (0, 255, 255)
                status = "PAUSE OK"
            else:
                color = (0, 0, 255)
                status = "TOO LONG"
            
            cv2.rectangle(image, (width - 300, 10), (width - 10, 100), (0, 0, 0), -1)
            cv2.rectangle(image, (width - 300, 10), (width - 10, 100), color, 3)
            cv2.putText(image, "FORWARD PAUSE", (width - 290, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            cv2.putText(image, status, (width - 290, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            cv2.putText(image, f"{self.pause_counter}f", (width - 290, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        return image
    
    def process_frame(self, frame):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        pose_results = self.pose.process(rgb_frame)
        face_results = self.face_mesh.process(rgb_frame)
        
        if pose_results.pose_landmarks:
            mp_drawing.draw_landmarks(frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
            
            landmarks = pose_results.pose_landmarks.landmark
            
            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,
                           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,
                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]
            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,
                        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]
            
            nose = landmarks[mp_pose.PoseLandmark.NOSE.value]
            head_y = int(nose.y * frame.shape[0])
            
            frame = self.draw_head_horizontal_line(frame, head_y)
            
            hip_angle = self.calculate_angle(left_shoulder, left_hip, left_knee)
            
            height, width = frame.shape[:2]
            hip_center = [int(left_hip[0] * width), int(left_hip[1] * height)]
            
            self.hip_angles.append(hip_angle)
            if hip_angle > self.max_angle:
                self.max_angle = hip_angle
            if hip_angle < self.min_angle:
                self.min_angle = hip_angle
            
            self.detect_forward_pause(hip_angle)
            
            frame = self.draw_hip_angle(frame, hip_angle, (int(hip_center[0]), int(hip_center[1])))
            frame = self.draw_pause_indicator(frame)
        
        if face_results.multi_face_landmarks:
            for face_landmarks in face_results.multi_face_landmarks:
                frame = self.draw_eye_gaze(frame, face_landmarks)
        
        return frame

# Streamlit UI
st.title("ğŸƒâ€â™‚ï¸ ãƒ­ãƒ¼ã‚¤ãƒ³ã‚°å§¿å‹¢è§£æã‚¢ãƒ—ãƒª")
st.markdown("**éª¨æ ¼ãƒˆãƒ¬ãƒ¼ã‚¹ã€è…°è§’åº¦æ¸¬å®šã€ç›®ç·šæ¤œå‡º**")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("âš™ï¸ è¨­å®š")
frame_skip = st.sidebar.slider("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ã‚­ãƒƒãƒ— (é«˜é€ŸåŒ–)", 1, 5, 1, 
                               help="æ•°å€¤ãŒå¤§ãã„ã»ã©é«˜é€Ÿå‡¦ç†",
                               key="main_frame_skip")

# å˜ä½“è§£æ
st.markdown("### ğŸ“¹ å‹•ç”»è§£æ")

uploaded_file = st.file_uploader("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=['mp4', 'avi', 'mov'], key="single_upload")

if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    
    analyzer = VideoAnalyzer()
    cap = cv2.VideoCapture(tfile.name)
    
    # UIè¦ç´ ã‚’äº‹å‰ã«å®šç¾©
    col1, col2 = st.columns([3, 1])
    
    with col1:
        stframe = st.empty()
        st.markdown("#### ğŸ¯ å‰æ–¹åœæ­¢æ¤œçŸ¥")
        pause_display = st.empty()
    
    with col2:
        st.markdown("### ğŸ“ˆ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿")
        current_display = st.empty()
        stats_display = st.empty()
    
    progress_bar = st.progress(0)
    
    if st.button("è§£æé–‹å§‹", key="single_analyze"):
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        current_frame = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            current_frame += 1
            if current_frame % frame_skip != 0:
                continue
            
            processed_frame = analyzer.process_frame(frame)
            if processed_frame is not None:
                stframe.image(processed_frame, channels="BGR")
            
            if analyzer.hip_angles:
                current_angle = analyzer.hip_angles[-1]
                
                current_display.markdown(f"""
                <div style='background-color: #1f4e79; padding: 15px; border-radius: 10px;'>
                    <h3 style='color: white; text-align: center; margin: 0;'>ç¾åœ¨ã®è§’åº¦</h3>
                    <h1 style='color: #00ff00; text-align: center; font-size: 36px; margin: 0;'>{current_angle:.1f}Â°</h1>
                </div>
                """, unsafe_allow_html=True)
                
                stats_display.markdown(f"""
                <div style='background-color: #2E2E2E; padding: 10px; border-radius: 8px; margin: 5px 0;'>
                    <h5 style='color: #FFD700; margin: 0;'>æœ€å¤§: {analyzer.max_angle:.1f}Â°</h5>
                    <h5 style='color: #98FB98; margin: 0;'>æœ€å°: {analyzer.min_angle:.1f}Â°</h5>
                    <h6 style='color: #87CEEB; margin: 0;'>ãƒ•ãƒ¬ãƒ¼ãƒ : {current_frame}/{frame_count}</h6>
                </div>
                """, unsafe_allow_html=True)
                
                # Forward pause display
                if analyzer.is_paused_forward and analyzer.pause_counter > 2:
                    if analyzer.pause_counter < 10:
                        status_color = "#27AE60"
                        status_text = "ğŸŸ¢ GOOD PAUSE"
                    elif analyzer.pause_counter < 20:
                        status_color = "#F39C12"
                        status_text = "ğŸŸ¡ PAUSE OK"
                    else:
                        status_color = "#E74C3C"
                        status_text = "ğŸ”´ TOO LONG"
                    
                    pause_display.markdown(f"""
                    <div style='background-color: {status_color}; padding: 20px; border-radius: 15px; text-align: center;'>
                        <h1 style='color: white; margin: 0; font-size: 42px;'>å‰æ–¹åœæ­¢</h1>
                        <h2 style='color: white; margin: 0;'>{status_text}</h2>
                        <h3 style='color: white; margin: 0;'>ç¶™ç¶šæ™‚é–“: {analyzer.pause_counter} ãƒ•ãƒ¬ãƒ¼ãƒ </h3>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    pause_display.markdown("""
                    <div style='background-color: #34495E; padding: 20px; border-radius: 10px; text-align: center;'>
                        <h3 style='color: #BDC3C7; margin: 0;'>ğŸ” å‰æ–¹åœæ­¢ã‚’ç›£è¦–ä¸­...</h3>
                    </div>
                    """, unsafe_allow_html=True)
            
            progress_bar.progress(current_frame / frame_count)
        
        cap.release()
        os.unlink(tfile.name)
        
        if analyzer.hip_angles:
            st.success("ğŸ‰ è§£æå®Œäº†ï¼")
            
            avg_angle = np.mean(analyzer.hip_angles)
            std_angle = np.std(analyzer.hip_angles)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æœ€å¤§è§’åº¦", f"{analyzer.max_angle:.1f}Â°")
            with col2:
                st.metric("æœ€å°è§’åº¦", f"{analyzer.min_angle:.1f}Â°")
            with col3:
                st.metric("å¹³å‡è§’åº¦", f"{avg_angle:.1f}Â°")
            with col4:
                st.metric("æ¨™æº–åå·®", f"{std_angle:.1f}Â°")
            
            # ã‚°ãƒ©ãƒ•
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(analyzer.hip_angles, color='blue', linewidth=2, label='è…°è§’åº¦')
            ax.axhline(y=analyzer.max_angle, color='red', linestyle='--', label=f'æœ€å¤§: {analyzer.max_angle:.1f}Â°')
            ax.axhline(y=analyzer.min_angle, color='green', linestyle='--', label=f'æœ€å°: {analyzer.min_angle:.1f}Â°')
            ax.axhline(y=avg_angle, color='orange', linestyle=':', label=f'å¹³å‡: {avg_angle:.1f}Â°')
            ax.set_xlabel('ãƒ•ãƒ¬ãƒ¼ãƒ æ•°')
            ax.set_ylabel('è§’åº¦ (åº¦)')
            ax.set_title('è…°è§’åº¦ã®æ™‚ç³»åˆ—å¤‰åŒ–')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

else:
    st.info("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
    st.markdown("""
    ### ğŸ¯ è§£ææ©Ÿèƒ½:
    - **éª¨æ ¼ãƒˆãƒ¬ãƒ¼ã‚¹**: MediaPipeã«ã‚ˆã‚‹å§¿å‹¢æ¤œå‡º
    - **é ­ã®åŸºæº–ç·š**: é ­ã®é«˜ã•ã«å›ºå®šã•ã‚ŒãŸæ°´å¹³ç·š
    - **è…°è§’åº¦æ¸¬å®š**: è‚©-è…°-è†ã®è§’åº¦ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¸¬å®š
    - **å‰æ–¹åœæ­¢æ¤œçŸ¥**: å‰æ–¹ä½ç½®ã§ã®åœæ­¢ã‚’æ¤œå‡º
    - **ç›®ç·šæ¤œå‡º**: çŸ¢å°ã«ã‚ˆã‚‹ç›®ç·šæ–¹å‘ã®è¡¨ç¤º
    - **çµ±è¨ˆæƒ…å ±**: æœ€å¤§ãƒ»æœ€å°ãƒ»å¹³å‡è§’åº¦ã¨æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•
    """)